{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG-ViEW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from collections import Counter\n",
    "import random\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with Robust Scaling, SMOTE 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data into correct format for tensorflow backend\n",
    "df_cnn_train = pd.read_csv(\"train.csv\", header=None)\n",
    "df_cnn_train = df_cnn_train.sample(frac=1)\n",
    "df_cnn_test = pd.read_csv(\"test.csv\", header=None)\n",
    "\n",
    "y_cnn = np.array(df_cnn_train[11].values).astype(np.int8)\n",
    "y_cnn=to_categorical(y_cnn)\n",
    "x_cnn = np.array(df_cnn_train[list(range(11))].values)[..., np.newaxis]\n",
    "y_cnn_test = np.array(df_cnn_test[11].values).astype(np.int8)\n",
    "x_cnn_test = np.array(df_cnn_test[list(range(11))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # number of categories in our problem\n",
    "    nclass = 2\n",
    "    \n",
    "    # shape of input\n",
    "    inp = Input(shape=(11, 1))\n",
    "    \n",
    "    # 1 -- 16 filters\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    img_1 = Dropout(rate=0.1)(img_1) #to prevent overfitting\n",
    "\n",
    "    # 2 -- 32 filters\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1) #to prevent overfitting\n",
    "    \n",
    "    # 3 -- 64 filters\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1) #to prevent overfitting\n",
    "    \n",
    "    # 2 -- 256 filters # NEW \n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1) #to prevent overfitting\n",
    "\n",
    "    \n",
    "    # 4 -- Dense layers\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\", kernel_regularizer=regularizers.l2(l=0.1))(img_1)\n",
    "    dense_1 = Dense(16, activation=activations.relu, name=\"dense_2\", kernel_regularizer=regularizers.l2(l=0.1))(dense_1)\n",
    "    dense_1 = Dense(nclass, activation=activations.softmax, name=\"dense_3_ecg_view\")(dense_1)\n",
    "    \n",
    "    \n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 11, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 7, 16)             96        \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 5, 32)             1568      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 5, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 3, 64)             6208      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1, 256)            49408     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_3_ecg_view (Dense)     (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 74,802\n",
      "Trainable params: 74,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 74878 samples, validate on 8320 samples\n",
      "Epoch 1/1000\n",
      " - 11s - loss: 0.6938 - acc: 0.7948 - val_loss: 0.3924 - val_acc: 0.8062\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.80625, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 2/1000\n",
      " - 9s - loss: 0.3796 - acc: 0.8172 - val_loss: 0.3615 - val_acc: 0.8280\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.80625 to 0.82800, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 3/1000\n",
      " - 9s - loss: 0.3574 - acc: 0.8326 - val_loss: 0.3365 - val_acc: 0.8464\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.82800 to 0.84639, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 4/1000\n",
      " - 9s - loss: 0.3446 - acc: 0.8395 - val_loss: 0.3300 - val_acc: 0.8487\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.84639 to 0.84868, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 5/1000\n",
      " - 12s - loss: 0.3369 - acc: 0.8454 - val_loss: 0.3196 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.84868 to 0.85457, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 6/1000\n",
      " - 11s - loss: 0.3296 - acc: 0.8482 - val_loss: 0.3199 - val_acc: 0.8569\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.85457 to 0.85685, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 7/1000\n",
      " - 13s - loss: 0.3229 - acc: 0.8524 - val_loss: 0.3113 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.85685 to 0.85709, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 8/1000\n",
      " - 10s - loss: 0.3183 - acc: 0.8528 - val_loss: 0.2990 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.85709 to 0.86214, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 9/1000\n",
      " - 10s - loss: 0.3148 - acc: 0.8566 - val_loss: 0.2927 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.86214 to 0.86719, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 10/1000\n",
      " - 10s - loss: 0.3101 - acc: 0.8596 - val_loss: 0.2916 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.86719\n",
      "Epoch 11/1000\n",
      " - 10s - loss: 0.3065 - acc: 0.8607 - val_loss: 0.2815 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.86719 to 0.87260, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 12/1000\n",
      " - 10s - loss: 0.3026 - acc: 0.8629 - val_loss: 0.2867 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.87260 to 0.87272, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 13/1000\n",
      " - 11s - loss: 0.3002 - acc: 0.8648 - val_loss: 0.2753 - val_acc: 0.8775\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.87272 to 0.87752, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 14/1000\n",
      " - 10s - loss: 0.2983 - acc: 0.8645 - val_loss: 0.2981 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.87752\n",
      "Epoch 15/1000\n",
      " - 11s - loss: 0.2960 - acc: 0.8666 - val_loss: 0.2729 - val_acc: 0.8808\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.87752 to 0.88077, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 16/1000\n",
      " - 11s - loss: 0.2919 - acc: 0.8681 - val_loss: 0.2822 - val_acc: 0.8755\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.88077\n",
      "Epoch 17/1000\n",
      " - 11s - loss: 0.2916 - acc: 0.8687 - val_loss: 0.2622 - val_acc: 0.8871\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.88077 to 0.88714, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 18/1000\n",
      " - 11s - loss: 0.2860 - acc: 0.8714 - val_loss: 0.2723 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.88714\n",
      "Epoch 19/1000\n",
      " - 12s - loss: 0.2850 - acc: 0.8725 - val_loss: 0.2560 - val_acc: 0.8907\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.88714 to 0.89075, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 20/1000\n",
      " - 10s - loss: 0.2833 - acc: 0.8731 - val_loss: 0.2532 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.89075 to 0.89339, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 21/1000\n",
      " - 9s - loss: 0.2809 - acc: 0.8755 - val_loss: 0.2525 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.89339 to 0.89603, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 22/1000\n",
      " - 9s - loss: 0.2800 - acc: 0.8758 - val_loss: 0.2443 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.89603 to 0.89627, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 23/1000\n",
      " - 8s - loss: 0.2769 - acc: 0.8779 - val_loss: 0.2453 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.89627 to 0.89976, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 24/1000\n",
      " - 11s - loss: 0.2757 - acc: 0.8785 - val_loss: 0.2428 - val_acc: 0.9006\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.89976 to 0.90060, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 25/1000\n",
      " - 10s - loss: 0.2733 - acc: 0.8796 - val_loss: 0.2425 - val_acc: 0.9007\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.90060 to 0.90072, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 26/1000\n",
      " - 9s - loss: 0.2725 - acc: 0.8805 - val_loss: 0.2534 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.90072\n",
      "Epoch 27/1000\n",
      " - 10s - loss: 0.2702 - acc: 0.8821 - val_loss: 0.2390 - val_acc: 0.8994\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.90072\n",
      "Epoch 28/1000\n",
      " - 9s - loss: 0.2684 - acc: 0.8829 - val_loss: 0.2436 - val_acc: 0.8975\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.90072\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 29/1000\n",
      " - 9s - loss: 0.2576 - acc: 0.8875 - val_loss: 0.2295 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.90072 to 0.90397, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 30/1000\n",
      " - 10s - loss: 0.2549 - acc: 0.8886 - val_loss: 0.2273 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.90397 to 0.90505, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 31/1000\n",
      " - 10s - loss: 0.2535 - acc: 0.8901 - val_loss: 0.2283 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.90505\n",
      "Epoch 32/1000\n",
      " - 12s - loss: 0.2520 - acc: 0.8907 - val_loss: 0.2250 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.90505 to 0.90781, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 33/1000\n",
      " - 10s - loss: 0.2510 - acc: 0.8907 - val_loss: 0.2221 - val_acc: 0.9082\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.90781 to 0.90817, saving model to baseline_cnn_ecgview.h5\n",
      "Epoch 34/1000\n",
      " - 10s - loss: 0.2507 - acc: 0.8902 - val_loss: 0.2248 - val_acc: 0.9061\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.90817\n",
      "Epoch 35/1000\n",
      " - 11s - loss: 0.2483 - acc: 0.8911 - val_loss: 0.2266 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.90817\n",
      "Epoch 36/1000\n",
      " - 9s - loss: 0.2509 - acc: 0.8907 - val_loss: 0.2266 - val_acc: 0.9055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00036: val_acc did not improve from 0.90817\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 37/1000\n",
      " - 9s - loss: 0.2485 - acc: 0.8926 - val_loss: 0.2238 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.90817\n",
      "Epoch 38/1000\n",
      " - 9s - loss: 0.2483 - acc: 0.8923 - val_loss: 0.2233 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.90817\n",
      "Epoch 00038: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "file_path = \"baseline_cnn_ecgview.h5\"\n",
    "\n",
    "# checkpointing the model's weight based on the accuracy of the model\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# set early stopping based on accuracy improving or not. It stops after 5 epochs of no accuracy improvement\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "\n",
    "# reduces learning rate when a metric has stopped improving\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "\n",
    "# defining the callbacks list to include the above parameters\n",
    "callbacks_list = [checkpoint, early, redonplat]\n",
    "\n",
    "# train the model\n",
    "model.fit(x_cnn, y_cnn, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "model.load_weights(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9106464490374091 \n",
      "Test ROC AUC score : 0.9251509818488605 \n",
      "Test accuracy score : 0.9178846153846154 \n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "pred_test = model.predict(x_cnn_test)\n",
    "pred_test = np.argmax(pred_test, axis=-1)\n",
    "\n",
    "# get f1 score of the model & print it. The f1 score considers the precision & recall.\n",
    "f1 = f1_score(y_cnn_test, pred_test, average=\"macro\")\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "# get ROC AUC score of the model & print it\n",
    "roc = roc_auc_score(y_cnn_test, pred_test)\n",
    "print(\"Test ROC AUC score : %s \"% roc)\n",
    "\n",
    "# get the accuracy and print it\n",
    "acc = accuracy_score(y_cnn_test, pred_test)\n",
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of using robust scaling\n",
    "Without robust scaling:\n",
    "* Test f1 score : 0.8389719144071639 \n",
    "* Test ROC AUC score : 0.8438790062228122 \n",
    "* Test accuracy score : 0.8546634615384615 \n",
    "\n",
    "With robust scaling:\n",
    "* Test f1 score : 0.9106464490374091 \n",
    "* Test ROC AUC score : 0.9251509818488605 \n",
    "* Test accuracy score : 0.9178846153846154 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
